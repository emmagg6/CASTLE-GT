CybORG v2.1, Scenario2, Commit Hash: Not using git
author: Dartmouth_Northeastern, team: BlueSTAR, technique: PPO + Greedy decoys + GT
wrappers: ChallengeWrapper2(env=env, agent_name='Blue')
Balance Point, 9400



steps: 30, adversary: B_lineAgent, mean: -27.272000000000002, standard deviation 0.5196816001334292

steps: 50, adversary: B_lineAgent, mean: -49.853100000000005, standard deviation 0.3746889866738732

steps: 100, adversary: B_lineAgent, mean: -106.23760000000001, standard deviation 0.3394231589153587

Steps: 30: PPO action-selection count: 0, CCE action-selection count: 180000, CCE precent: 1.0

Steps: 50: PPO action-selection count: 0, CCE action-selection count: 180000, CCE precent: 1.0

Steps: 100: PPO action-selection count: 0, CCE action-selection count: 180000, CCE precent: 1.0



Note: Red is Meander Agent. Balance point: 9400, PPO: 10000.pth, CCE: 10000cce.pkl 
